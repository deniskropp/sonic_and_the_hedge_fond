{"output":"## `utils/LiveMusicHelper.ts`\n\nThis utility class acts as the primary bridge between the frontend components and the `@google/genai` library for real-time music generation. It manages the connection to the AI model, processes incoming audio data, handles prompt weighting, and controls the playback state.\n\n### Purpose\n\n- Facilitate real-time music generation by interacting with the Google Generative AI API.\n- Process and manage audio chunks received from the AI model.\n- Control the playback state (playing, paused, stopped, loading).\n- Handle prompt filtering and dispatch notifications for filtered prompts.\n- Allow for external audio processing nodes (e.g., audio level analysis) to be connected.\n\n### Key Properties\n\n*   `ai`: An instance of `GoogleGenAI` used to interact with the API.\n*   `model`: The identifier for the AI music generation model.\n*   `session`: The current `LiveMusicSession` object, representing the active connection to the AI service. It is initialized lazily.\n*   `sessionPromise`: A promise that resolves to the `LiveMusicSession`, used for managing concurrent connection attempts.\n*   `connectionError`: A boolean flag indicating if a connection error has occurred.\n*   `filteredPrompts`: A `Set` storing the text of prompts that have been filtered by the AI.\n*   `nextStartTime`: The scheduled start time for the next audio chunk in the `AudioContext`.\n*   `bufferTime`: A buffer period (in seconds) to ensure smooth playback initiation.\n*   `audioContext`: The Web Audio API `AudioContext` used for audio processing and playback.\n*   `extraDestination`: An optional `AudioNode` where audio can be routed for additional processing (e.g., `AudioAnalyser`).\n*   `outputNode`: A `GainNode` used to control the volume of the audio output.\n*   `playbackState`: The current state of the music playback (`stopped`, `playing`, `loading`, `paused`).\n*   `prompts`: A `Map` storing the current state of all prompts, including their text, weight, CC mapping, and color.\n\n### Core Methods\n\n*   `getSession()`: Returns the `LiveMusicSession`, establishing a connection if one does not already exist.\n*   `connect()`: Establishes a connection to the AI music generation service. It sets up callbacks for message handling (`onmessage`), errors (`onerror`), and connection closure (`onclose`).\n*   `setPlaybackState(state: PlaybackState)`: Updates the internal `playbackState` and dispatches a `playback-state-changed` event.\n*   `processAudioChunks(audioChunks: AudioChunk[])`: Decodes and schedules the playback of received audio data chunks using the `AudioContext`. It manages `nextStartTime` to ensure smooth, sequential playback and handles state transitions based on buffer timing.\n*   `activePrompts` (getter): Returns an array of prompts that are currently active (not filtered and have a weight greater than 0).\n*   `setWeightedPrompts(prompts: Map<string, Prompt>)`: Updates the AI model with the current set of weighted prompts. This method is throttled to prevent excessive API calls. It filters out inactive prompts before sending the update.\n*   `play()`: Initiates the music playback. It ensures a session is established, updates prompts, resumes the `AudioContext`, and starts the audio output.\n*   `pause()`: Pauses the music playback. It stops the AI session, sets the state to `paused`, and fades out the audio output.\n*   `stop()`: Stops the music playback entirely. It closes the AI session, resets playback state and timing, and fades out the audio output.\n*   `playPause()`: Toggles the playback state between playing, paused, and stopped based on the current `playbackState`.\n\n### Event Dispatches\n\n*   `playback-state-changed`: Dispatched whenever the `playbackState` property changes, providing the new state.\n*   `filtered-prompt`: Dispatched when the AI model filters out a prompt. Includes details about the filtered prompt and the reason for filtering.\n*   `error`: Dispatched when a connection error or other critical issue occurs.\n","artifact":{"task":"T42","files":[{"path":"utils/LiveMusicHelper.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nimport type { PlaybackState, Prompt } from '../types';\nimport type { AudioChunk, GoogleGenAI, LiveMusicFilteredPrompt, LiveMusicServerMessage, LiveMusicSession } from '@google/genai';\nimport { decode, decodeAudioData } from './audio';\nimport { throttle } from './throttle';\n\n/**\n * ## `utils/LiveMusicHelper.ts`\n *\n * This utility class acts as the primary bridge between the frontend components and the `@google/genai` library for real-time music generation. It manages the connection to the AI model, processes incoming audio data, handles prompt weighting, and controls the playback state.\n *\n * ### Purpose\n *\n * - Facilitate real-time music generation by interacting with the Google Generative AI API.\n * - Process and manage audio chunks received from the AI model.\n * - Control the playback state (playing, paused, stopped, loading).\n * - Handle prompt filtering and dispatch notifications for filtered prompts.\n * - Allow for external audio processing nodes (e.g., audio level analysis) to be connected.\n *\n * ### Key Properties\n *\n * *   `ai`: An instance of `GoogleGenAI` used to interact with the API.\n * *   `model`: The identifier for the AI music generation model.\n * *   `session`: The current `LiveMusicSession` object, representing the active connection to the AI service. It is initialized lazily.\n * *   `sessionPromise`: A promise that resolves to the `LiveMusicSession`, used for managing concurrent connection attempts.\n * *   `connectionError`: A boolean flag indicating if a connection error has occurred.\n * *   `filteredPrompts`: A `Set` storing the text of prompts that have been filtered by the AI.\n * *   `nextStartTime`: The scheduled start time for the next audio chunk in the `AudioContext`.\n * *   `bufferTime`: A buffer period (in seconds) to ensure smooth playback initiation.\n * *   `audioContext`: The Web Audio API `AudioContext` used for audio processing and playback.\n * *   `extraDestination`: An optional `AudioNode` where audio can be routed for additional processing (e.g., `AudioAnalyser`).\n * *   `outputNode`: A `GainNode` used to control the volume of the audio output.\n * *   `playbackState`: The current state of the music playback (`stopped`, `playing`, `loading`, `paused`).\n * *   `prompts`: A `Map` storing the current state of all prompts, including their text, weight, CC mapping, and color.\n *\n * ### Core Methods\n *\n * *   `getSession()`: Returns the `LiveMusicSession`, establishing a connection if one does not already exist.\n * *   `connect()`: Establishes a connection to the AI music generation service. It sets up callbacks for message handling (`onmessage`), errors (`onerror`), and connection closure (`onclose`).\n * *   `setPlaybackState(state: PlaybackState)`: Updates the internal `playbackState` and dispatches a `playback-state-changed` event.\n * *   `processAudioChunks(audioChunks: AudioChunk[])`: Decodes and schedules the playback of received audio data chunks using the `AudioContext`. It manages `nextStartTime` to ensure smooth, sequential playback and handles state transitions based on buffer timing.\n * *   `activePrompts` (getter): Returns an array of prompts that are currently active (not filtered and have a weight greater than 0).\n * *   `setWeightedPrompts(prompts: Map<string, Prompt>)`: Updates the AI model with the current set of weighted prompts. This method is throttled to prevent excessive API calls. It filters out inactive prompts before sending the update.\n * *   `play()`: Initiates the music playback. It ensures a session is established, updates prompts, resumes the `AudioContext`, and starts the audio output.\n * *   `pause()`: Pauses the music playback. It stops the AI session, sets the state to `paused`, and fades out the audio output.\n * *   `stop()`: Stops the music playback entirely. It closes the AI session, resets playback state and timing, and fades out the audio output.\n * *   `playPause()`: Toggles the playback state between playing, paused, and stopped based on the current `playbackState`.\n *\n * ### Event Dispatches\n *\n * *   `playback-state-changed`: Dispatched whenever the `playbackState` property changes, providing the new state.\n * *   `filtered-prompt`: Dispatched when the AI model filters out a prompt. Includes details about the filtered prompt and the reason for filtering.\n * *   `error`: Dispatched when a connection error or other critical issue occurs.\n *\n */\nexport class LiveMusicHelper extends EventTarget {\n\n  private ai: GoogleGenAI;\n  private model: string;\n\n  private session: LiveMusicSession | null = null;\n  private sessionPromise: Promise<LiveMusicSession> | null = null;\n\n  private connectionError = true;\n\n  private filteredPrompts = new Set<string>();\n  private nextStartTime = 0;\n  private bufferTime = 2;\n\n  public readonly audioContext: AudioContext;\n  public extraDestination: AudioNode | null = null;\n\n  private outputNode: GainNode;\n  private playbackState: PlaybackState = 'stopped';\n\n  private prompts: Map<string, Prompt>;\n\n  constructor(ai: GoogleGenAI, model: string) {\n    super();\n    this.ai = ai;\n    this.model = model;\n    this.prompts = new Map();\n    this.audioContext = new AudioContext({ sampleRate: 48000 });\n    this.outputNode = this.audioContext.createGain();\n  }\n\n  private getSession(): Promise<LiveMusicSession> {\n    if (!this.sessionPromise) this.sessionPromise = this.connect();\n    return this.sessionPromise;\n  }\n\n  private async connect(): Promise<LiveMusicSession> {\n    this.sessionPromise = this.ai.live.music.connect({\n      model: this.model,\n      callbacks: {\n        onmessage: async (e: LiveMusicServerMessage) => {\n          if (e.setupComplete) {\n            this.connectionError = false;\n          }\n          if (e.filteredPrompt) {\n            // Store the filtered prompt text for client-side filtering.\n            this.filteredPrompts = new Set([...this.filteredPrompts, e.filteredPrompt.text!])\n            // Dispatch an event to notify the UI about the filtered prompt and its reason.\n            this.dispatchEvent(new CustomEvent<LiveMusicFilteredPrompt>('filtered-prompt', { detail: e.filteredPrompt }));\n          }\n          if (e.serverContent?.audioChunks) {\n            await this.processAudioChunks(e.serverContent.audioChunks);\n          }\n        },\n        onerror: () => {\n          this.connectionError = true;\n          this.stop();\n          this.dispatchEvent(new CustomEvent('error', { detail: 'Connection error, please restart audio.' }));\n        },\n        onclose: () => {\n          this.connectionError = true;\n          this.stop();\n          this.dispatchEvent(new CustomEvent('error', { detail: 'Connection error, please restart audio.' }));\n        },\n      },\n    });\n    return this.sessionPromise;\n  }\n\n  private setPlaybackState(state: PlaybackState) {\n    this.playbackState = state;\n    this.dispatchEvent(new CustomEvent('playback-state-changed', { detail: state }));\n  }\n\n  private async processAudioChunks(audioChunks: AudioChunk[]) {\n    // Do not process audio if paused or stopped.\n    if (this.playbackState === 'paused' || this.playbackState === 'stopped') return;\n    \n    // Decode the audio data from the received chunks.\n    const audioBuffer = await decodeAudioData(\n      decode(audioChunks[0].data!),\n      this.audioContext,\n      48000,\n      2,\n    );\n    \n    const source = this.audioContext.createBufferSource();\n    source.buffer = audioBuffer;\n    source.connect(this.outputNode);\n\n    // If this is the first chunk after a pause/stop, schedule it after a buffer time.\n    if (this.nextStartTime === 0) {\n      this.nextStartTime = this.audioContext.currentTime + this.bufferTime;\n      // Set playback to 'playing' after the buffer time has elapsed.\n      setTimeout(() => {\n        this.setPlaybackState('playing');\n      }, this.bufferTime * 1000);\n    }\n    \n    // If the next start time is already in the past, it indicates a delay or issue, reset and flag as loading.\n    if (this.nextStartTime < this.audioContext.currentTime) {\n      this.setPlaybackState('loading');\n      this.nextStartTime = 0;\n      return;\n    }\n    \n    // Schedule the audio chunk to play at the calculated start time.\n    source.start(this.nextStartTime);\n    // Update the next start time based on the duration of the current chunk.\n    this.nextStartTime += audioBuffer.duration;\n  }\n\n  /** \n   * Returns prompts that are not filtered and have a weight greater than 0. \n   * These are the prompts that will be sent to the AI model.\n   */\n  public get activePrompts() {\n    return Array.from(this.prompts.values())\n      .filter((p) => {\n        // Filter out prompts that are client-side filtered or have zero weight.\n        return !this.filteredPrompts.has(p.text) && p.weight !== 0;\n      })\n  }\n\n  /**\n   * Updates the AI model with the current set of weighted prompts. \n   * This method is throttled to prevent overwhelming the AI API with rapid updates.\n   * It filters out inactive prompts before sending the update.\n   */\n  public readonly setWeightedPrompts = throttle(async (prompts: Map<string, Prompt>) => {\n    this.prompts = prompts;\n\n    // Ensure there is at least one active prompt; otherwise, stop playback and notify the user.\n    if (this.activePrompts.length === 0) {\n      this.dispatchEvent(new CustomEvent('error', { detail: 'There needs to be one active prompt to play.' }));\n      this.pause();\n      return;\n    }\n\n    // If the session is not yet established, store the prompts to be set later.\n    // A user interaction is required before `setWeightedPrompts` can be called successfully.\n    if (!this.session) return;\n\n    try {\n      // Send the active prompts to the AI model.\n      await this.session.setWeightedPrompts({\n        weightedPrompts: this.activePrompts,\n      });\n    } catch (e: any) {\n      // Dispatch an error event if setting prompts fails.\n      this.dispatchEvent(new CustomEvent('error', { detail: e.message }));\n      this.pause();\n    }\n  }, 200); // Throttle delay of 200ms\n\n  /**\n   * Initiates music playback.\n   * Ensures a session is established, updates prompts, resumes the AudioContext, and starts the audio output.\n   */\n  public async play() {\n    this.setPlaybackState('loading');\n    this.session = await this.getSession();\n    await this.setWeightedPrompts(this.prompts);\n    this.audioContext.resume();\n    this.session.play();\n    this.outputNode.connect(this.audioContext.destination);\n    if (this.extraDestination) this.outputNode.connect(this.extraDestination);\n    // Fade in the audio output.\n    this.outputNode.gain.setValueAtTime(0, this.audioContext.currentTime);\n    this.outputNode.gain.linearRampToValueAtTime(1, this.audioContext.currentTime + 0.1);\n  }\n\n  /**\n   * Pauses music playback.\n   * Stops the AI session, sets the state to `paused`, and fades out the audio output.\n   */\n  public pause() {\n    if (this.session) this.session.pause();\n    this.setPlaybackState('paused');\n    // Fade out the audio output.\n    this.outputNode.gain.setValueAtTime(1, this.audioContext.currentTime);\n    this.outputNode.gain.linearRampToValueAtTime(0, this.audioContext.currentTime + 0.1);\n    this.nextStartTime = 0; // Reset start time for smooth resume.\n    // Recreate the output node to ensure a clean state after pausing.\n    this.outputNode = this.audioContext.createGain();\n  }\n\n  /**\n   * Stops music playback entirely.\n   * Closes the AI session, resets playback state and timing, and fades out the audio output.\n   */\n  public stop() {\n    if (this.session) this.session.stop();\n    this.setPlaybackState('stopped');\n    // Fade out the audio output.\n    this.outputNode.gain.setValueAtTime(0, this.audioContext.currentTime);\n    this.outputNode.gain.linearRampToValueAtTime(1, this.audioContext.currentTime + 0.1);\n    this.nextStartTime = 0;\n    // Clear the session and promise to allow for reconnection.\n    this.session = null;\n    this.sessionPromise = null;\n  }\n\n  /**\n   * Toggles the playback state between playing, paused, and stopped.\n   * If the current state is 'loading', it stops playback.\n   */\n  public async playPause() {\n    switch (this.playbackState) {\n      case 'playing':\n        return this.pause();\n      case 'paused':\n      case 'stopped':\n        return this.play();\n      case 'loading':\n        return this.stop();\n    }\n  }\n\n}\n"}]},"team":null,"reasoning":"The user requested the revision of the documentation for `utils/LiveMusicHelper.ts`. I have incorporated the feedback from the documentation reviewer into the existing documentation, addressing the points raised regarding clarity on AI interaction, the purpose of throttling, the `activePrompts` getter, and error handling details. The revised documentation is now more comprehensive and adheres to the project's documentation standards."}