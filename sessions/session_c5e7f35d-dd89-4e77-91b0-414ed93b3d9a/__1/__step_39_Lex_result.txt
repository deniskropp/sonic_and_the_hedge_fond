{"output":"## `utils/LiveMusicHelper.ts`\n\nThis file contains the `LiveMusicHelper` class, which acts as the primary interface between the frontend application and the Google Generative AI's music generation model (`lyria-realtime-exp`). It manages the connection to the AI, processes incoming audio data, handles playback state, and integrates with prompt management from the frontend.\n\n### Purpose\n\n- **AI Model Interaction:** Establishes and maintains a connection to the specified Google Generative AI music model.\n- **Real-time Audio Processing:** Receives audio chunks from the AI, decodes them, and schedules them for playback.\n- **Playback Control:** Manages the playback state (`stopped`, `playing`, `loading`, `paused`) and controls the audio output.\n- **Prompt Management Integration:** Accepts weighted prompts from the frontend and sends them to the AI model. It also handles filtered prompts from the AI and dispatches them as events.\n- **Audio Context Management:** Initializes and manages the `AudioContext` for audio playback and analysis.\n\n### Key Properties\n\n- `ai`: An instance of `GoogleGenAI` for interacting with the AI model.\n- `model`: The identifier for the specific AI music model being used (e.g., `lyria-realtime-exp`).\n- `session`: The current `LiveMusicSession` object, representing the active connection to the AI.\n- `sessionPromise`: A promise that resolves to the `LiveMusicSession`, used for managing the connection lifecycle.\n- `connectionError`: A boolean flag indicating if there's an active connection error.\n- `filteredPrompts`: A `Set` storing the text of prompts that have been filtered by the AI.\n- `nextStartTime`: The scheduled start time for the next audio chunk in the `AudioContext`.\n- `bufferTime`: A buffer duration (in seconds) to ensure smooth playback.\n- `audioContext`: The `AudioContext` instance for handling all audio operations.\n- `extraDestination`: An optional `AudioNode` where audio can be routed for additional processing (e.g., `AudioAnalyser`).\n- `outputNode`: A `GainNode` used to control the volume of the audio output.\n- `playbackState`: The current state of the music playback.\n- `prompts`: A `Map` storing the current state of all defined prompts, including their weights and CC mappings.\n\n### Core Methods\n\n- **`constructor(ai: GoogleGenAI, model: string)`**: Initializes the helper with the AI instance and model name. Sets up the `AudioContext` and output gain node.\n- **`getSession(): Promise<LiveMusicSession>`**: Returns the existing session promise or initiates a new connection if none exists.\n- **`connect(): Promise<LiveMusicSession>`**: Establishes the connection to the AI model, setting up callbacks for messages, errors, and connection closure.\n  - `onmessage`: Processes incoming messages, including setup completion, filtered prompts, and audio chunks.\n  - `onerror` / `onclose`: Handles connection errors and updates the `playbackState` and flags.\n- **`setPlaybackState(state: PlaybackState)`**: Updates the internal `playbackState` and dispatches a `playback-state-changed` event.\n- **`processAudioChunks(audioChunks: AudioChunk[])`**: Decodes incoming audio data chunks and schedules them for playback using `AudioBufferSourceNode`. It manages `nextStartTime` to ensure smooth transitions and detects if playback needs to reset due to buffer underflow.\n- **`get activePrompts()`**: A getter that returns an array of prompts that are currently active (not filtered and have a weight greater than 0).\n- **`setWeightedPrompts(prompts: Map<string, Prompt>)`**: (Throttled) Updates the AI model with the current set of weighted prompts. It filters out inactive or filtered prompts before sending them.\n- **`play()`**: Initiates music playback. Connects the audio nodes, resumes the `AudioContext`, and calls the AI session's `play()` method.\n- **`pause()`**: Pauses music playback. Stops the AI session, updates the `playbackState`, and ramps down the output volume.\n- **`stop()`**: Stops music playback entirely. Stops the AI session, resets playback state and timing, and disconnects the session.\n- **`playPause()`**: Toggles between playing and pausing the music based on the current `playbackState`.\n\n### Event Dispatches\n\n- **`playback-state-changed`**: Dispatched whenever the `playbackState` changes, providing the new state.\n- **`filtered-prompt`**: Dispatched when the AI model filters out a prompt, providing details about the filtered prompt and the reason.\n- **`error`**: Dispatched when a connection error or other issue occurs.\n\n### Interaction with AI Model\n\nThe `LiveMusicHelper` class is central to the AI interaction. It:\n1.  **Initiates Connection:** Uses `GoogleGenAI` to connect to the specified model.\n2.  **Sends Prompts:** Calls `session.setWeightedPrompts()` with the currently active and weighted prompts. This is crucial for guiding the AI's music generation.\n3.  **Receives Audio:** Processes `audioChunks` received from the AI via the `onmessage` callback.\n4.  **Handles AI Feedback:** Reacts to `filteredPrompt` messages from the AI, informing the UI and updating the internal state.\n\n### Audio Processing and Playback Control\n\n- Audio is received as base64 encoded chunks.\n- The `decode` and `decodeAudioData` utilities are used to convert these chunks into an `AudioBuffer`.\n- An `AudioBufferSourceNode` is created for each buffer.\n- These sources are connected to an `outputNode` (a `GainNode`).\n- The `outputNode` is connected to the `AudioContext.destination` and potentially an `extraDestination` (like `AudioAnalyser`).\n- `nextStartTime` and `bufferTime` are used to precisely schedule when each audio chunk should start playing, ensuring a continuous stream and handling buffering.\n- The `playbackState` property accurately reflects the current status (playing, paused, stopped, loading), and events are dispatched accordingly.","artifact":{"task":"T40","files":[{"path":"utils/LiveMusicHelper.ts","content":"## `utils/LiveMusicHelper.ts`\n\nThis file contains the `LiveMusicHelper` class, which acts as the primary interface between the frontend application and the Google Generative AI's music generation model (`lyria-realtime-exp`). It manages the connection to the AI, processes incoming audio data, handles playback state, and integrates with prompt management from the frontend.\n\n### Purpose\n\n- **AI Model Interaction:** Establishes and maintains a connection to the specified Google Generative AI music model.\n- **Real-time Audio Processing:** Receives audio chunks from the AI, decodes them, and schedules them for playback.\n- **Playback Control:** Manages the playback state (`stopped`, `playing`, `loading`, `paused`) and controls the audio output.\n- **Prompt Management Integration:** Accepts weighted prompts from the frontend and sends them to the AI model. It also handles filtered prompts from the AI and dispatches them as events.\n- **Audio Context Management:** Initializes and manages the `AudioContext` for audio playback and analysis.\n\n### Key Properties\n\n- `ai`: An instance of `GoogleGenAI` for interacting with the AI model.\n- `model`: The identifier for the specific AI music model being used (e.g., `lyria-realtime-exp`).\n- `session`: The current `LiveMusicSession` object, representing the active connection to the AI.\n- `sessionPromise`: A promise that resolves to the `LiveMusicSession`, used for managing the connection lifecycle.\n- `connectionError`: A boolean flag indicating if there's an active connection error.\n- `filteredPrompts`: A `Set` storing the text of prompts that have been filtered by the AI.\n- `nextStartTime`: The scheduled start time for the next audio chunk in the `AudioContext`.\n- `bufferTime`: A buffer duration (in seconds) to ensure smooth playback.\n- `audioContext`: The `AudioContext` instance for handling all audio operations.\n- `extraDestination`: An optional `AudioNode` where audio can be routed for additional processing (e.g., `AudioAnalyser`).\n- `outputNode`: A `GainNode` used to control the volume of the audio output.\n- `playbackState`: The current state of the music playback.\n- `prompts`: A `Map` storing the current state of all defined prompts, including their weights and CC mappings.\n\n### Core Methods\n\n- **`constructor(ai: GoogleGenAI, model: string)`**: Initializes the helper with the AI instance and model name. Sets up the `AudioContext` and output gain node.\n- **`getSession(): Promise<LiveMusicSession>`**: Returns the existing session promise or initiates a new connection if none exists.\n- **`connect(): Promise<LiveMusicSession>`**: Establishes the connection to the AI model, setting up callbacks for messages, errors, and connection closure.\n  - `onmessage`: Processes incoming messages, including setup completion, filtered prompts, and audio chunks.\n  - `onerror` / `onclose`: Handles connection errors and updates the `playbackState` and flags.\n- **`setPlaybackState(state: PlaybackState)`**: Updates the internal `playbackState` and dispatches a `playback-state-changed` event.\n- **`processAudioChunks(audioChunks: AudioChunk[])`**: Decodes incoming audio data chunks and schedules them for playback using `AudioBufferSourceNode`. It manages `nextStartTime` to ensure smooth transitions and detects if playback needs to reset due to buffer underflow.\n- **`get activePrompts()`**: A getter that returns an array of prompts that are currently active (not filtered and have a weight greater than 0).\n- **`setWeightedPrompts(prompts: Map<string, Prompt>)`**: (Throttled) Updates the AI model with the current set of weighted prompts. It filters out inactive or filtered prompts before sending them.\n- **`play()`**: Initiates music playback. Connects the audio nodes, resumes the `AudioContext`, and calls the AI session's `play()` method.\n- **`pause()`**: Pauses music playback. Stops the AI session, updates the `playbackState`, and ramps down the output volume.\n- **`stop()`**: Stops music playback entirely. Stops the AI session, resets playback state and timing, and disconnects the session.\n- **`playPause()`**: Toggles between playing and pausing the music based on the current `playbackState`.\n\n### Event Dispatches\n\n- **`playback-state-changed`**: Dispatched whenever the `playbackState` changes, providing the new state.\n- **`filtered-prompt`**: Dispatched when the AI model filters out a prompt, providing details about the filtered prompt and the reason.\n- **`error`**: Dispatched when a connection error or other issue occurs.\n\n### Interaction with AI Model\n\nThe `LiveMusicHelper` class is central to the AI interaction. It:\n1.  **Initiates Connection:** Uses `GoogleGenAI` to connect to the specified model.\n2.  **Sends Prompts:** Calls `session.setWeightedPrompts()` with the currently active and weighted prompts. This is crucial for guiding the AI's music generation.\n3.  **Receives Audio:** Processes `audioChunks` received from the AI via the `onmessage` callback.\n4.  **Handles AI Feedback:** Reacts to `filteredPrompt` messages from the AI, informing the UI and updating the internal state.\n\n### Audio Processing and Playback Control\n\n- Audio is received as base64 encoded chunks.\n- The `decode` and `decodeAudioData` utilities are used to convert these chunks into an `AudioBuffer`.\n- An `AudioBufferSourceNode` is created for each buffer.\n- These sources are connected to an `outputNode` (a `GainNode`).\n- The `outputNode` is connected to the `AudioContext.destination` and potentially an `extraDestination` (like `AudioAnalyser`).\n- `nextStartTime` and `bufferTime` are used to precisely schedule when each audio chunk should start playing, ensuring a continuous stream and handling buffering.\n- The `playbackState` property accurately reflects the current status (playing, paused, stopped, loading), and events are dispatched accordingly."}]},"team":null,"reasoning":null}