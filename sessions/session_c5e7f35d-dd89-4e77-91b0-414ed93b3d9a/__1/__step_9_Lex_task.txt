The overall goal is: 'Document the PromptDJ MIDI myfirstanalog project'

Your role's specific goal is: 'Generate clear, concise, and accurate technical documentation based on provided specifications, source code, and developer notes.'
Your specific sub-task is: 'Generate documentation for the 'metadata.json' file, explaining its purpose and key fields.'

The team's roles are:
    {"high_level_goal":"Document the PromptDJ MIDI myfirstanalog project","reasoning":"The user wants documentation for the provided codebase. This plan breaks down the documentation process into manageable steps, assigning writing and review tasks to specialized agents.","roles":[{"title":"Documentation Writer","purpose":"To generate clear, concise, and accurate technical documentation based on provided specifications, source code, and developer notes."},{"title":"Documentation Reviewer","purpose":"To review documentation drafts for clarity, technical accuracy, grammatical correctness, and adherence to project style guides, providing constructive feedback for improvement."},{"title":"Task-Agnostic Step (TAS) extractor","purpose":"To identify and return each 'Task Agnostic Step' (TAS) towards the high-level goal."},{"title":"AI Tutor","purpose":"To facilitate knowledge transfer between agents and ensure consistent understanding of project goals and documentation standards."},{"title":"Prompt Engineer","purpose":"To structure workflows and ensure clarity in agent instructions, including system prompt engineering."}],"tasks":[{"id":"T1","description":"Identify all Task Agnostic Steps (TAS) required to document the PromptDJ MIDI myfirstanalog project.","role":"Task-Agnostic Step (TAS) extractor","agent":"uTASe","requires":[]},{"id":"T2","description":"For each identified TAS, create a detailed system prompt for the Documentation Writer (Lex) and Documentation Reviewer (Critique) agents. Ensure prompts are clear, actionable, and aligned with the project's goals.","role":"Prompt Engineer","agent":"Lyra","requires":["T1"]},{"id":"T3","description":"Provide context and knowledge transfer to Lex and Critique regarding the PromptDJ MIDI myfirstanalog project, its architecture, and the specific documentation requirements for each TAS.","role":"AI Tutor","agent":"AI Tutor","requires":["T2"]},{"id":"T4","description":"Generate documentation for the 'README.md' file. This includes summarizing the project's purpose, features, and setup instructions based on the provided content.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T5","description":"Review the generated documentation for 'README.md' for accuracy, clarity, and completeness. Provide feedback to Lex.","role":"Documentation Reviewer","agent":"Critique","requires":["T4"]},{"id":"T6","description":"Revise the 'README.md' documentation based on feedback from Critique.","role":"Documentation Writer","agent":"Lex","requires":["T5"]},{"id":"T7","description":"Generate documentation for the 'package.json' file. Focus on explaining the project's dependencies and scripts.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T8","description":"Review the generated documentation for 'package.json'.","role":"Documentation Reviewer","agent":"Critique","requires":["T7"]},{"id":"T9","description":"Revise the 'package.json' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T8"]},{"id":"T10","description":"Generate documentation for the 'metadata.json' file, explaining its purpose and key fields.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T11","description":"Review the generated documentation for 'metadata.json'.","role":"Documentation Reviewer","agent":"Critique","requires":["T10"]},{"id":"T12","description":"Revise the 'metadata.json' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T11"]},{"id":"T13","description":"Generate documentation for the 'tsconfig.json' file, explaining its configuration options for TypeScript compilation.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T14","description":"Review the generated documentation for 'tsconfig.json'.","role":"Documentation Reviewer","agent":"Critique","requires":["T13"]},{"id":"T15","description":"Revise the 'tsconfig.json' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T14"]},{"id":"T16","description":"Generate documentation for the 'components/PlayPauseButton.ts' file, explaining its functionality, properties, and rendering logic.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T17","description":"Review the generated documentation for 'components/PlayPauseButton.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T16"]},{"id":"T18","description":"Revise the 'components/PlayPauseButton.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T17"]},{"id":"T19","description":"Generate documentation for the 'components/PromptController.ts' file, detailing its role in managing prompts, MIDI CC mapping, and user input.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T20","description":"Review the generated documentation for 'components/PromptController.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T19"]},{"id":"T21","description":"Revise the 'components/PromptController.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T20"]},{"id":"T22","description":"Generate documentation for the 'components/PromptDjMidi.ts' file, explaining its grid layout, prompt management, MIDI input handling, and playback controls.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T23","description":"Review the generated documentation for 'components/PromptDjMidi.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T22"]},{"id":"T24","description":"Revise the 'components/PromptDjMidi.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T23"]},{"id":"T25","description":"Generate documentation for the 'components/ToastMessage.ts' file, describing its function for displaying user notifications.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T26","description":"Review the generated documentation for 'components/ToastMessage.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T25"]},{"id":"T27","description":"Revise the 'components/ToastMessage.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T26"]},{"id":"T28","description":"Generate documentation for the 'components/WeightKnob.ts' file, explaining its visual representation of prompt weight and its interactive features.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T29","description":"Review the generated documentation for 'components/WeightKnob.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T28"]},{"id":"T30","description":"Revise the 'components/WeightKnob.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T29"]},{"id":"T31","description":"Generate documentation for the 'index.tsx' file, covering the main application setup, component integration, and event handling.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T32","description":"Review the generated documentation for 'index.tsx'.","role":"Documentation Reviewer","agent":"Critique","requires":["T31"]},{"id":"T33","description":"Revise the 'index.tsx' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T32"]},{"id":"T34","description":"Generate documentation for the 'types.ts' file, defining the core data structures and types used throughout the project.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T35","description":"Review the generated documentation for 'types.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T34"]},{"id":"T36","description":"Revise the 'types.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T35"]},{"id":"T37","description":"Generate documentation for the 'utils/AudioAnalyser.ts' file, explaining its role in analyzing audio levels.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T38","description":"Review the generated documentation for 'utils/AudioAnalyser.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T37"]},{"id":"T39","description":"Revise the 'utils/AudioAnalyser.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T38"]},{"id":"T40","description":"Generate documentation for the 'utils/LiveMusicHelper.ts' file, detailing its interaction with the AI model, audio processing, and playback control.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T41","description":"Review the generated documentation for 'utils/LiveMusicHelper.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T40"]},{"id":"T42","description":"Revise the 'utils/LiveMusicHelper.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T41"]},{"id":"T43","description":"Generate documentation for the 'utils/MidiDispatcher.ts' file, explaining its MIDI message handling and event dispatching.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T44","description":"Review the generated documentation for 'utils/MidiDispatcher.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T43"]},{"id":"T45","description":"Revise the 'utils/MidiDispatcher.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T44"]},{"id":"T46","description":"Generate documentation for the 'utils/audio.ts' file, covering audio encoding, decoding, and blob creation utilities.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T47","description":"Review the generated documentation for 'utils/audio.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T46"]},{"id":"T48","description":"Revise the 'utils/audio.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T47"]},{"id":"T49","description":"Generate documentation for the 'utils/throttle.ts' file, explaining the throttling utility function.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T50","description":"Review the generated documentation for 'utils/throttle.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T49"]},{"id":"T51","description":"Revise the 'utils/throttle.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T50"]},{"id":"T52","description":"Generate documentation for the 'vite.config.ts' file, explaining the Vite configuration for the project.","role":"Documentation Writer","agent":"Lex","requires":["T3"]},{"id":"T53","description":"Review the generated documentation for 'vite.config.ts'.","role":"Documentation Reviewer","agent":"Critique","requires":["T52"]},{"id":"T54","description":"Revise the 'vite.config.ts' documentation.","role":"Documentation Writer","agent":"Lex","requires":["T53"]},{"id":"T55","description":"Consolidate all reviewed and revised documentation into a final, coherent document set for the PromptDJ MIDI myfirstanalog project.","role":"Documentation Orchestrator","agent":"Scribe","requires":["T6","T9","T12","T15","T18","T21","T24","T27","T30","T33","T36","T39","T42","T45","T48","T51","T54"]}]}

Please use the following outputs from the other agents as your input:

--- Artifact 'files' from (User) in [initial]:
{"task":"initial","files":[{"path":"README.md","content":"<div align=\"center\">\n\n<img width=\"1200\" height=\"475\" alt=\"GHBanner\" src=\"https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6\" />\n\n  <h1>Built with AI Studio</h2>\n\n  <p>The fastest path from prompt to production with Gemini.</p>\n\n  <a href=\"https://aistudio.google.com/apps\">Start building</a>\n\n</div>\n"},{"path":"package.json","content":"{\n  \"name\": \"promptdj-midi-myfirstanalog\",\n  \"private\": true,\n  \"version\": \"0.0.0\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"vite build\",\n    \"preview\": \"vite preview\"\n  },\n  \"dependencies\": {\n    \"@google/genai\": \"^1.0.0\",\n    \"lit\": \"^3.3.0\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^22.14.0\",\n    \n    \"typescript\": \"~5.8.2\",\n    \"vite\": \"^6.2.0\"\n  }\n}\n"},{"path":"metadata.json","content":"{\n  \"name\": \"PromptDJ MIDI myfirstanalog\",\n  \"description\": \"Control real time music with a MIDI controller.\",\n  \"requestFramePermissions\": [],\n  \"prompt\": \"\"\n}"},{"path":"tsconfig.json","content":"{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"experimentalDecorators\": true,\n    \"useDefineForClassFields\": false,\n    \"module\": \"ESNext\",\n    \"lib\": [\n      \"ES2022\",\n      \"DOM\",\n      \"DOM.Iterable\"\n    ],\n    \"skipLibCheck\": true,\n    \"types\": [\n      \"node\"\n    ],\n    \"moduleResolution\": \"bundler\",\n    \"isolatedModules\": true,\n    \"moduleDetection\": \"force\",\n    \"allowJs\": true,\n    \"jsx\": \"react-jsx\",\n    \"paths\": {\n      \"@/*\": [\n        \"./*\"\n      ]\n    },\n    \"allowImportingTsExtensions\": true,\n    \"noEmit\": true\n  }\n}"},{"path":"components/PlayPauseButton.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nimport { svg, css, html, LitElement } from 'lit';\nimport { customElement, property } from 'lit/decorators.js';\nimport type { PlaybackState } from '../types';\n\n@customElement('play-pause-button')\nexport class PlayPauseButton extends LitElement {\n\n  @property({ type: String }) playbackState: PlaybackState = 'stopped';\n\n  static override styles = css`\n    :host {\n      position: relative;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      pointer-events: none;\n    }\n    :host(:hover) svg {\n      transform: scale(1.2);\n    }\n    svg {\n      width: 100%;\n      height: 100%;\n      transition: transform 0.5s cubic-bezier(0.25, 1.56, 0.32, 0.99);\n    }\n    .hitbox {\n      pointer-events: all;\n      position: absolute;\n      width: 65%;\n      aspect-ratio: 1;\n      top: 9%;\n      border-radius: 50%;\n      cursor: pointer;\n    }\n    .loader {\n      stroke: #ffffff;\n      stroke-width: 3;\n      stroke-linecap: round;\n      animation: spin linear 1s infinite;\n      transform-origin: center;\n      transform-box: fill-box;\n    }\n    @keyframes spin {\n      from { transform: rotate(0deg); }\n      to { transform: rotate(359deg); }\n    }\n  `;\n\n  private renderSvg() {\n    return html` <svg\n      width=\"140\"\n      height=\"140\"\n      viewBox=\"0 -10 140 150\"\n      fill=\"none\"\n      xmlns=\"http://www.w3.org/2000/svg\">\n      <rect\n        x=\"22\"\n        y=\"6\"\n        width=\"96\"\n        height=\"96\"\n        rx=\"48\"\n        fill=\"black\"\n        fill-opacity=\"0.05\" />\n      <rect\n        x=\"23.5\"\n        y=\"7.5\"\n        width=\"93\"\n        height=\"93\"\n        rx=\"46.5\"\n        stroke=\"black\"\n        stroke-opacity=\"0.3\"\n        stroke-width=\"3\" />\n      <g filter=\"url(#filter0_ddi_1048_7373)\">\n        <rect\n          x=\"25\"\n          y=\"9\"\n          width=\"90\"\n          height=\"90\"\n          rx=\"45\"\n          fill=\"white\"\n          fill-opacity=\"0.05\"\n          shape-rendering=\"crispEdges\" />\n      </g>\n      ${this.renderIcon()}\n      <defs>\n        <filter\n          id=\"filter0_ddi_1048_7373\"\n          x=\"0\"\n          y=\"0\"\n          width=\"140\"\n          height=\"140\"\n          filterUnits=\"userSpaceOnUse\"\n          color-interpolation-filters=\"sRGB\">\n          <feFlood flood-opacity=\"0\" result=\"BackgroundImageFix\" />\n          <feColorMatrix\n            in=\"SourceAlpha\"\n            type=\"matrix\"\n            values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0\"\n            result=\"hardAlpha\" />\n          <feOffset dy=\"2\" />\n          <feGaussianBlur stdDeviation=\"4\" />\n          <feComposite in2=\"hardAlpha\" operator=\"out\" />\n          <feColorMatrix\n            type=\"matrix\"\n            values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0\" />\n          <feBlend\n            mode=\"normal\"\n            in2=\"BackgroundImageFix\"\n            result=\"effect1_dropShadow_1048_7373\" />\n          <feColorMatrix\n            in=\"SourceAlpha\"\n            type=\"matrix\"\n            values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0\"\n            result=\"hardAlpha\" />\n          <feOffset dy=\"16\" />\n          <feGaussianBlur stdDeviation=\"12.5\" />\n          <feComposite in2=\"hardAlpha\" operator=\"out\" />\n          <feColorMatrix\n            type=\"matrix\"\n            values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0\" />\n          <feBlend\n            mode=\"normal\"\n            in2=\"effect1_dropShadow_1048_7373\"\n            result=\"effect2_dropShadow_1048_7373\" />\n          <feBlend\n            mode=\"normal\"\n            in=\"SourceGraphic\"\n            in2=\"effect2_dropShadow_1048_7373\"\n            result=\"shape\" />\n          <feColorMatrix\n            in=\"SourceAlpha\"\n            type=\"matrix\"\n            values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0\"\n            result=\"hardAlpha\" />\n          <feOffset dy=\"3\" />\n          <feGaussianBlur stdDeviation=\"1.5\" />\n          <feComposite in2=\"hardAlpha\" operator=\"arithmetic\" k2=\"-1\" k3=\"1\" />\n          <feColorMatrix\n            type=\"matrix\"\n            values=\"0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0.05 0\" />\n          <feBlend\n            mode=\"normal\"\n            in2=\"shape\"\n            result=\"effect3_innerShadow_1048_7373\" />\n        </filter>\n      </defs>\n    </svg>`;\n  }\n\n  private renderPause() {\n    return svg`<path\n      d=\"M75.0037 69V39H83.7537V69H75.0037ZM56.2537 69V39H65.0037V69H56.2537Z\"\n      fill=\"#FEFEFE\"\n    />`;\n  }\n\n  private renderPlay() {\n    return svg`<path d=\"M60 71.5V36.5L87.5 54L60 71.5Z\" fill=\"#FEFEFE\" />`;\n  }\n\n  private renderLoading() {\n    return svg`<path shape-rendering=\"crispEdges\" class=\"loader\" d=\"M70,74.2L70,74.2c-10.7,0-19.5-8.7-19.5-19.5l0,0c0-10.7,8.7-19.5,19.5-19.5\n            l0,0c10.7,0,19.5,8.7,19.5,19.5l0,0\"/>`;\n  }\n\n  private renderIcon() {\n    if (this.playbackState === 'playing') {\n      return this.renderPause();\n    } else if (this.playbackState === 'loading') {\n      return this.renderLoading();\n    } else {\n      return this.renderPlay();\n    }\n  }\n\n  override render() {\n    return html`${this.renderSvg()}<div class=\"hitbox\"></div>`;\n  }\n}\n\ndeclare global {\n  interface HTMLElementTagNameMap {\n    'play-pause-button': PlayPauseButton\n  }\n}\n"},{"path":"components/PromptController.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nimport { css, html, LitElement } from 'lit';\nimport { customElement, property, query } from 'lit/decorators.js';\nimport { classMap } from 'lit/directives/class-map.js';\n\nimport './WeightKnob';\nimport type { WeightKnob } from './WeightKnob';\n\nimport type { MidiDispatcher } from '../utils/MidiDispatcher';\nimport type { Prompt, ControlChange } from '../types';\n\n/** A single prompt input associated with a MIDI CC. */\n@customElement('prompt-controller')\nexport class PromptController extends LitElement {\n  static override styles = css`\n    .prompt {\n      width: 100%;\n      display: flex;\n      flex-direction: column;\n      align-items: center;\n      justify-content: center;\n    }\n    weight-knob {\n      width: 70%;\n      flex-shrink: 0;\n    }\n    #midi {\n      font-family: monospace;\n      text-align: center;\n      font-size: 1.5vmin;\n      border: 0.2vmin solid #fff;\n      border-radius: 0.5vmin;\n      padding: 2px 5px;\n      color: #fff;\n      background: #0006;\n      cursor: pointer;\n      visibility: hidden;\n      user-select: none;\n      margin-top: 0.75vmin;\n      .learn-mode & {\n        color: orange;\n        border-color: orange;\n      }\n      .show-cc & {\n        visibility: visible;\n      }\n    }\n    #text {\n      font-weight: 500;\n      font-size: 1.8vmin;\n      max-width: 17vmin;\n      min-width: 2vmin;\n      padding: 0.1em 0.3em;\n      margin-top: 0.5vmin;\n      flex-shrink: 0;\n      border-radius: 0.25vmin;\n      text-align: center;\n      white-space: pre;\n      overflow: hidden;\n      border: none;\n      outline: none;\n      -webkit-font-smoothing: antialiased;\n      background: #000;\n      color: #fff;\n      &:not(:focus) {\n        text-overflow: ellipsis;\n      }\n    }\n    :host([filtered]) {\n      weight-knob { \n        opacity: 0.5;\n      }\n      #text {\n        background: #da2000;\n        z-index: 1;\n      }\n    }\n    @media only screen and (max-width: 600px) {\n      #text {\n        font-size: 2.3vmin;\n      }\n      weight-knob {\n        width: 60%;\n      }\n    }\n  `;\n\n  @property({ type: String }) promptId = '';\n  @property({ type: String }) text = '';\n  @property({ type: Number }) weight = 0;\n  @property({ type: String }) color = '';\n  @property({ type: Boolean, reflect: true }) filtered = false;\n\n  @property({ type: Number }) cc = 0;\n  @property({ type: Number }) channel = 0; // Not currently used\n\n  @property({ type: Boolean }) learnMode = false;\n  @property({ type: Boolean }) showCC = false;\n\n  @query('weight-knob') private weightInput!: WeightKnob;\n  @query('#text') private textInput!: HTMLInputElement;\n\n  @property({ type: Object })\n  midiDispatcher: MidiDispatcher | null = null;\n\n  @property({ type: Number }) audioLevel = 0;\n\n  private lastValidText!: string;\n\n  override connectedCallback() {\n    super.connectedCallback();\n    this.midiDispatcher?.addEventListener('cc-message', (e: Event) => {\n      const customEvent = e as CustomEvent<ControlChange>;\n      const { channel, cc, value } = customEvent.detail;\n      if (this.learnMode) {\n        this.cc = cc;\n        this.channel = channel;\n        this.learnMode = false;\n        this.dispatchPromptChange();\n      } else if (cc === this.cc) {\n        this.weight = (value / 127) * 2;\n        this.dispatchPromptChange();\n      }\n    });\n  }\n\n  override firstUpdated() {\n    // contenteditable is applied to textInput so we can \"shrink-wrap\" to text width\n    // It's set here and not render() because Lit doesn't believe it's a valid attribute.\n    this.textInput.setAttribute('contenteditable', 'plaintext-only');\n\n    // contenteditable will do weird things if this is part of the template.\n    this.textInput.textContent = this.text;\n    this.lastValidText = this.text;\n  }\n\n  update(changedProperties: Map<string, unknown>) {\n    if (changedProperties.has('showCC') && !this.showCC) {\n      this.learnMode = false;\n    }\n    if (changedProperties.has('text') && this.textInput) {\n      this.textInput.textContent = this.text;\n    }\n    super.update(changedProperties);\n  }\n\n  private dispatchPromptChange() {\n    this.dispatchEvent(\n      new CustomEvent<Prompt>('prompt-changed', {\n        detail: {\n          promptId: this.promptId,\n          text: this.text,\n          weight: this.weight,\n          cc: this.cc,\n          color: this.color,\n        },\n      }),\n    );\n  }\n\n  private onKeyDown(e: KeyboardEvent) {\n    if (e.key === 'Enter') {\n      e.preventDefault();\n      this.textInput.blur();\n    }\n    if (e.key === 'Escape') {\n      e.preventDefault();\n      this.resetText();\n      this.textInput.blur();\n    }\n  }\n\n  private resetText() {\n    this.text = this.lastValidText;\n    this.textInput.textContent = this.lastValidText;\n  }\n\n  private async updateText() {\n    const newText = this.textInput.textContent?.trim();\n    if (!newText) {\n      this.resetText();\n    } else {\n      this.text = newText;\n      this.lastValidText = newText;\n    }\n    this.dispatchPromptChange();\n    // Show the prompt from the beginning if it's cropped\n    this.textInput.scrollLeft = 0;\n  }\n\n  private onFocus() {\n    // .select() for contenteditable doesn't work.\n    const selection = window.getSelection();\n    if (!selection) return;\n    const range = document.createRange();\n    range.selectNodeContents(this.textInput);\n    selection.removeAllRanges();\n    selection.addRange(range);\n  }\n\n  private updateWeight() {\n    this.weight = this.weightInput.value;\n    this.dispatchPromptChange();\n  }\n\n  private toggleLearnMode() {\n    this.learnMode = !this.learnMode;\n  }\n\n  override render() {\n    const classes = classMap({\n      'prompt': true,\n      'learn-mode': this.learnMode,\n      'show-cc': this.showCC,\n    });\n    return html`<div class=${classes}>\n      <weight-knob\n        id=\"weight\"\n        value=${this.weight}\n        color=${this.filtered ? '#888' : this.color}\n        audioLevel=${this.filtered ? 0 : this.audioLevel}\n        @input=${this.updateWeight}></weight-knob>\n      <span\n        id=\"text\"\n        spellcheck=\"false\"\n        @focus=${this.onFocus}\n        @keydown=${this.onKeyDown}\n        @blur=${this.updateText}></span>\n      <div id=\"midi\" @click=${this.toggleLearnMode}>\n        ${this.learnMode ? 'Learn' : `CC:${this.cc}`}\n      </div>\n    </div>`;\n  }\n}\n\ndeclare global {\n  interface HTMLElementTagNameMap {\n    'prompt-controller': PromptController;\n  }\n} \n"},{"path":"components/PromptDjMidi.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nimport { css, html, LitElement } from 'lit';\nimport { customElement, property, state } from 'lit/decorators.js';\nimport { styleMap } from 'lit/directives/style-map.js';\n\nimport { throttle } from '../utils/throttle';\n\nimport './PromptController';\nimport './PlayPauseButton';\nimport type { PlaybackState, Prompt } from '../types';\nimport { MidiDispatcher } from '../utils/MidiDispatcher';\n\n/** The grid of prompt inputs. */\n@customElement('prompt-dj-midi')\nexport class PromptDjMidi extends LitElement {\n  static override styles = css`\n    :host {\n      height: 100%;\n      display: flex;\n      flex-direction: column;\n      justify-content: center;\n      align-items: center;\n      box-sizing: border-box;\n      position: relative;\n    }\n    #background {\n      will-change: background-image;\n      position: absolute;\n      height: 100%;\n      width: 100%;\n      z-index: -1;\n      background: #111;\n    }\n    #grid {\n      width: 80vmin;\n      height: 80vmin;\n      display: grid;\n      grid-template-columns: repeat(4, 1fr);\n      gap: 2.5vmin;\n      margin-top: 8vmin;\n    }\n    prompt-controller {\n      width: 100%;\n    }\n    play-pause-button {\n      position: relative;\n      width: 15vmin;\n    }\n    #buttons {\n      position: absolute;\n      top: 0;\n      left: 0;\n      padding: 5px;\n      display: flex;\n      gap: 5px;\n    }\n    button {\n      font: inherit;\n      font-weight: 600;\n      cursor: pointer;\n      color: #fff;\n      background: #0002;\n      -webkit-font-smoothing: antialiased;\n      border: 1.5px solid #fff;\n      border-radius: 4px;\n      user-select: none;\n      padding: 3px 6px;\n      &.active {\n        background-color: #fff;\n        color: #000;\n      }\n    }\n    select {\n      font: inherit;\n      padding: 5px;\n      background: #fff;\n      color: #000;\n      border-radius: 4px;\n      border: none;\n      outline: none;\n      cursor: pointer;\n    }\n  `;\n\n  private prompts: Map<string, Prompt>;\n  private midiDispatcher: MidiDispatcher;\n\n  @property({ type: Boolean }) private showMidi = false;\n  @property({ type: String }) public playbackState: PlaybackState = 'stopped';\n  @state() public audioLevel = 0;\n  @state() private midiInputIds: string[] = [];\n  @state() private activeMidiInputId: string | null = null;\n\n  @property({ type: Object })\n  private filteredPrompts = new Set<string>();\n\n  constructor(\n    initialPrompts: Map<string, Prompt>,\n  ) {\n    super();\n    this.prompts = initialPrompts;\n    this.midiDispatcher = new MidiDispatcher();\n  }\n\n  private handlePromptChanged(e: CustomEvent<Prompt>) {\n    const { promptId, text, weight, cc } = e.detail;\n    const prompt = this.prompts.get(promptId);\n\n    if (!prompt) {\n      console.error('prompt not found', promptId);\n      return;\n    }\n\n    prompt.text = text;\n    prompt.weight = weight;\n    prompt.cc = cc;\n\n    const newPrompts = new Map(this.prompts);\n    newPrompts.set(promptId, prompt);\n\n    this.prompts = newPrompts;\n    this.requestUpdate();\n\n    this.dispatchEvent(\n      new CustomEvent('prompts-changed', { detail: this.prompts }),\n    );\n  }\n\n  /** Generates radial gradients for each prompt based on weight and color. */\n  private readonly makeBackground = throttle(\n    () => {\n      const clamp01 = (v: number) => Math.min(Math.max(v, 0), 1);\n\n      const MAX_WEIGHT = 0.5;\n      const MAX_ALPHA = 0.6;\n\n      const bg: string[] = [];\n\n      [...this.prompts.values()].forEach((p, i) => {\n        const alphaPct = clamp01(p.weight / MAX_WEIGHT) * MAX_ALPHA;\n        const alpha = Math.round(alphaPct * 0xff)\n          .toString(16)\n          .padStart(2, '0');\n\n        const stop = p.weight / 2;\n        const x = (i % 4) / 3;\n        const y = Math.floor(i / 4) / 3;\n        const s = `radial-gradient(circle at ${x * 100}% ${y * 100}%, ${p.color}${alpha} 0px, ${p.color}00 ${stop * 100}%)`;\n\n        bg.push(s);\n      });\n\n      return bg.join(', ');\n    },\n    30, // don't re-render more than once every XXms\n  );\n\n  private toggleShowMidi() {\n    return this.setShowMidi(!this.showMidi);\n  }\n\n  public async setShowMidi(show: boolean) {\n    this.showMidi = show;\n    if (!this.showMidi) return;\n    try {\n      const inputIds = await this.midiDispatcher.getMidiAccess();\n      this.midiInputIds = inputIds;\n      this.activeMidiInputId = this.midiDispatcher.activeMidiInputId;\n    } catch (e) {\n      this.showMidi = false;\n      this.dispatchEvent(new CustomEvent('error', {detail: e.message}));\n    }\n  }\n\n  private handleMidiInputChange(event: Event) {\n    const selectElement = event.target as HTMLSelectElement;\n    const newMidiId = selectElement.value;\n    this.activeMidiInputId = newMidiId;\n    this.midiDispatcher.activeMidiInputId = newMidiId;\n  }\n\n  private playPause() {\n    this.dispatchEvent(new CustomEvent('play-pause'));\n  }\n\n  public addFilteredPrompt(prompt: string) {\n    this.filteredPrompts = new Set([...this.filteredPrompts, prompt]);\n  }\n\n  override render() {\n    const bg = styleMap({\n      backgroundImage: this.makeBackground(),\n    });\n    return html`<div id=\"background\" style=${bg}></div>\n      <div id=\"buttons\">\n        <button\n          @click=${this.toggleShowMidi}\n          class=${this.showMidi ? 'active' : ''}\n          >MIDI</button\n        >\n        <select\n          @change=${this.handleMidiInputChange}\n          .value=${this.activeMidiInputId || ''}\n          style=${this.showMidi ? '' : 'visibility: hidden'}>\n          ${this.midiInputIds.length > 0\n        ? this.midiInputIds.map(\n          (id) =>\n            html`<option value=${id}>\n                    ${this.midiDispatcher.getDeviceName(id)}\n                  </option>`,\n        )\n        : html`<option value=\"\">No devices found</option>`}\n        </select>\n      </div>\n      <div id=\"grid\">${this.renderPrompts()}</div>\n      <play-pause-button .playbackState=${this.playbackState} @click=${this.playPause}></play-pause-button>`;\n  }\n\n  private renderPrompts() {\n    return [...this.prompts.values()].map((prompt) => {\n      return html`<prompt-controller\n        promptId=${prompt.promptId}\n        ?filtered=${this.filteredPrompts.has(prompt.text)}\n        cc=${prompt.cc}\n        text=${prompt.text}\n        weight=${prompt.weight}\n        color=${prompt.color}\n        .midiDispatcher=${this.midiDispatcher}\n        .showCC=${this.showMidi}\n        audioLevel=${this.audioLevel}\n        @prompt-changed=${this.handlePromptChanged}>\n      </prompt-controller>`;\n    });\n  }\n}\n"},{"path":"components/ToastMessage.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nimport { css, html, LitElement } from 'lit';\nimport { customElement, property } from 'lit/decorators.js';\nimport { classMap } from 'lit/directives/class-map.js';\n\n@customElement('toast-message')\nexport class ToastMessage extends LitElement {\n  static override styles = css`\n    .toast {\n      line-height: 1.6;\n      position: fixed;\n      top: 20px;\n      left: 50%;\n      transform: translateX(-50%);\n      background-color: #000;\n      color: white;\n      padding: 15px;\n      border-radius: 5px;\n      display: flex;\n      align-items: center;\n      justify-content: space-between;\n      gap: 15px;\n      width: min(450px, 80vw);\n      transition: transform 0.5s cubic-bezier(0.19, 1, 0.22, 1);\n      border: 2px solid #fff;\n      box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.5);\n      text-wrap: pretty;\n    }\n    button {\n      border-radius: 100px;\n      aspect-ratio: 1;\n      border: none;\n      color: #000;\n      cursor: pointer;\n    }\n    .toast:not(.showing) {\n      transition-duration: 1s;\n      transform: translate(-50%, -200%);\n    }\n    a {\n      color: #acacac;\n      text-decoration: underline;\n    }\n  `;\n\n  @property({ type: String }) message = '';\n  @property({ type: Boolean }) showing = false;\n\n  private renderMessageWithLinks() {\n    const urlRegex = /(https?:\\/\\/[^\\s]+)/g;\n    const parts = this.message.split( urlRegex );\n    return parts.map( ( part, i ) => {\n      if ( i % 2 === 0 ) return part;\n      return html`<a href=${part} target=\"_blank\" rel=\"noopener\">${part}</a>`;\n    } );\n  }\n\n  override render() {\n    return html`<div class=${classMap({ showing: this.showing, toast: true })}>\n      <div class=\"message\">${this.renderMessageWithLinks()}</div>\n      <button @click=${this.hide}>✕</button>\n    </div>`;\n  }\n\n  show(message: string) {\n    this.showing = true;\n    this.message = message;\n  }\n\n  hide() {\n    this.showing = false;\n  }\n\n}\n\ndeclare global {\n  interface HTMLElementTagNameMap {\n    'toast-message': ToastMessage\n  }\n}\n"},{"path":"components/WeightKnob.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nimport { css, html, LitElement } from 'lit';\nimport { customElement, property } from 'lit/decorators.js';\nimport { styleMap } from 'lit/directives/style-map.js';\n\n/** Maps prompt weight to halo size. */\nconst MIN_HALO_SCALE = 1;\nconst MAX_HALO_SCALE = 2;\n\n/** The amount of scale to add to the halo based on audio level. */\nconst HALO_LEVEL_MODIFIER = 1;\n\n/** A knob for adjusting and visualizing prompt weight. */\n@customElement('weight-knob')\nexport class WeightKnob extends LitElement {\n  static override styles = css`\n    :host {\n      cursor: grab;\n      position: relative;\n      width: 100%;\n      aspect-ratio: 1;\n      flex-shrink: 0;\n      touch-action: none;\n    }\n    svg {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n    }\n    #halo {\n      position: absolute;\n      z-index: -1;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n      border-radius: 50%;\n      mix-blend-mode: lighten;\n      transform: scale(2);\n      will-change: transform;\n    }\n  `;\n\n  @property({ type: Number }) value = 0;\n  @property({ type: String }) color = '#000';\n  @property({ type: Number }) audioLevel = 0;\n\n  private dragStartPos = 0;\n  private dragStartValue = 0;\n\n  constructor() {\n    super();\n    this.handlePointerDown = this.handlePointerDown.bind(this);\n    this.handlePointerMove = this.handlePointerMove.bind(this);\n    this.handlePointerUp = this.handlePointerUp.bind(this);\n  }\n\n  private handlePointerDown(e: PointerEvent) {\n    e.preventDefault();\n    this.dragStartPos = e.clientY;\n    this.dragStartValue = this.value;\n    document.body.classList.add('dragging');\n    window.addEventListener('pointermove', this.handlePointerMove);\n    window.addEventListener('pointerup', this.handlePointerUp);\n  }\n\n  private handlePointerMove(e: PointerEvent) {\n    const delta = this.dragStartPos - e.clientY;\n    this.value = this.dragStartValue + delta * 0.01;\n    this.value = Math.max(0, Math.min(2, this.value));\n    this.dispatchEvent(new CustomEvent<number>('input', { detail: this.value }));\n  }\n\n  private handlePointerUp() {\n    window.removeEventListener('pointermove', this.handlePointerMove);\n    window.removeEventListener('pointerup', this.handlePointerUp);\n    document.body.classList.remove('dragging');\n  }\n\n  private handleWheel(e: WheelEvent) {\n    const delta = e.deltaY;\n    this.value = this.value + delta * -0.0025;\n    this.value = Math.max(0, Math.min(2, this.value));\n    this.dispatchEvent(new CustomEvent<number>('input', { detail: this.value }));\n  }\n\n  private describeArc(\n    centerX: number,\n    centerY: number,\n    startAngle: number,\n    endAngle: number,\n    radius: number,\n  ): string {\n    const startX = centerX + radius * Math.cos(startAngle);\n    const startY = centerY + radius * Math.sin(startAngle);\n    const endX = centerX + radius * Math.cos(endAngle);\n    const endY = centerY + radius * Math.sin(endAngle);\n\n    const largeArcFlag = endAngle - startAngle <= Math.PI ? '0' : '1';\n\n    return (\n      `M ${startX} ${startY}` +\n      `A ${radius} ${radius} 0 ${largeArcFlag} 1 ${endX} ${endY}`\n    );\n  }\n\n  override render() {\n    const rotationRange = Math.PI * 2 * 0.75;\n    const minRot = -rotationRange / 2 - Math.PI / 2;\n    const maxRot = rotationRange / 2 - Math.PI / 2;\n    const rot = minRot + (this.value / 2) * (maxRot - minRot);\n    const dotStyle = styleMap({\n      transform: `translate(40px, 40px) rotate(${rot}rad)`,\n    });\n\n    let scale = (this.value / 2) * (MAX_HALO_SCALE - MIN_HALO_SCALE);\n    scale += MIN_HALO_SCALE;\n    scale += this.audioLevel * HALO_LEVEL_MODIFIER;\n\n    const haloStyle = styleMap({\n      display: this.value > 0 ? 'block' : 'none',\n      background: this.color,\n      transform: `scale(${scale})`,\n    });\n\n    return html`\n      <div id=\"halo\" style=${haloStyle}></div>\n      <!-- Static SVG elements -->\n      ${this.renderStaticSvg()}\n      <!-- SVG elements that move, separated to limit redraws -->\n      <svg\n        viewBox=\"0 0 80 80\"\n        @pointerdown=${this.handlePointerDown}\n        @wheel=${this.handleWheel}>\n        <g style=${dotStyle}>\n          <circle cx=\"14\" cy=\"0\" r=\"2\" fill=\"#000\" />\n        </g>\n        <path\n          d=${this.describeArc(40, 40, minRot, maxRot, 34.5)}\n          fill=\"none\"\n          stroke=\"#0003\"\n          stroke-width=\"3\"\n          stroke-linecap=\"round\" />\n        <path\n          d=${this.describeArc(40, 40, minRot, rot, 34.5)}\n          fill=\"none\"\n          stroke=\"#fff\"\n          stroke-width=\"3\"\n          stroke-linecap=\"round\" />\n      </svg>\n    `;\n  }\n  \n  private renderStaticSvg() { \n    return html`<svg viewBox=\"0 0 80 80\">\n        <ellipse\n          opacity=\"0.4\"\n          cx=\"40\"\n          cy=\"40\"\n          rx=\"40\"\n          ry=\"40\"\n          fill=\"url(#f1)\" />\n        <g filter=\"url(#f2)\">\n          <ellipse cx=\"40\" cy=\"40\" rx=\"29\" ry=\"29\" fill=\"url(#f3)\" />\n        </g>\n        <g filter=\"url(#f4)\">\n          <circle cx=\"40\" cy=\"40\" r=\"20.6667\" fill=\"url(#f5)\" />\n        </g>\n        <circle cx=\"40\" cy=\"40\" r=\"18\" fill=\"url(#f6)\" />\n        <defs>\n          <filter\n            id=\"f2\"\n            x=\"8.33301\"\n            y=\"10.0488\"\n            width=\"63.333\"\n            height=\"64\"\n            filterUnits=\"userSpaceOnUse\"\n            color-interpolation-filters=\"sRGB\">\n            <feFlood flood-opacity=\"0\" result=\"BackgroundImageFix\" />\n            <feColorMatrix\n              in=\"SourceAlpha\"\n              type=\"matrix\"\n              values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0\"\n              result=\"hardAlpha\" />\n            <feOffset dy=\"2\" />\n            <feGaussianBlur stdDeviation=\"1.5\" />\n            <feComposite in2=\"hardAlpha\" operator=\"out\" />\n            <feColorMatrix\n              type=\"matrix\"\n              values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0\" />\n            <feBlend mode=\"normal\" in2=\"BackgroundImageFix\" result=\"shadow1\" />\n            <feBlend\n              mode=\"normal\"\n              in=\"SourceGraphic\"\n              in2=\"shadow1\"\n              result=\"shape\" />\n          </filter>\n          <filter\n            id=\"f4\"\n            x=\"11.333\"\n            y=\"19.0488\"\n            width=\"57.333\"\n            height=\"59.334\"\n            filterUnits=\"userSpaceOnUse\"\n            color-interpolation-filters=\"sRGB\">\n            <feFlood flood-opacity=\"0\" result=\"BackgroundImageFix\" />\n            <feColorMatrix\n              in=\"SourceAlpha\"\n              type=\"matrix\"\n              values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0\"\n              result=\"hardAlpha\" />\n            <feOffset dy=\"10\" />\n            <feGaussianBlur stdDeviation=\"4\" />\n            <feComposite in2=\"hardAlpha\" operator=\"out\" />\n            <feColorMatrix\n              type=\"matrix\"\n              values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0\" />\n            <feBlend mode=\"normal\" in2=\"BackgroundImageFix\" result=\"shadow1\" />\n            <feColorMatrix\n              in=\"SourceAlpha\"\n              type=\"matrix\"\n              values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0\"\n              result=\"hardAlpha\" />\n            <feMorphology\n              radius=\"5\"\n              operator=\"erode\"\n              in=\"SourceAlpha\"\n              result=\"shadow2\" />\n            <feOffset dy=\"8\" />\n            <feGaussianBlur stdDeviation=\"3\" />\n            <feComposite in2=\"hardAlpha\" operator=\"out\" />\n            <feColorMatrix\n              type=\"matrix\"\n              values=\"0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0\" />\n            <feBlend mode=\"normal\" in2=\"shadow1\" result=\"shadow2\" />\n            <feBlend\n              mode=\"normal\"\n              in=\"SourceGraphic\"\n              in2=\"shadow2\"\n              result=\"shape\" />\n          </filter>\n          <linearGradient\n            id=\"f1\"\n            x1=\"40\"\n            y1=\"0\"\n            x2=\"40\"\n            y2=\"80\"\n            gradientUnits=\"userSpaceOnUse\">\n            <stop stop-opacity=\"0.5\" />\n            <stop offset=\"1\" stop-color=\"white\" stop-opacity=\"0.3\" />\n          </linearGradient>\n          <radialGradient\n            id=\"f3\"\n            cx=\"0\"\n            cy=\"0\"\n            r=\"1\"\n            gradientUnits=\"userSpaceOnUse\"\n            gradientTransform=\"translate(40 40) rotate(90) scale(29 29)\">\n            <stop offset=\"0.6\" stop-color=\"white\" />\n            <stop offset=\"1\" stop-color=\"white\" stop-opacity=\"0.7\" />\n          </radialGradient>\n          <linearGradient\n            id=\"f5\"\n            x1=\"40\"\n            y1=\"19.0488\"\n            x2=\"40\"\n            y2=\"60.3822\"\n            gradientUnits=\"userSpaceOnUse\">\n            <stop stop-color=\"white\" />\n            <stop offset=\"1\" stop-color=\"#F2F2F2\" />\n          </linearGradient>\n          <linearGradient\n            id=\"f6\"\n            x1=\"40\"\n            y1=\"21.7148\"\n            x2=\"40\"\n            y2=\"57.7148\"\n            gradientUnits=\"userSpaceOnUse\">\n            <stop stop-color=\"#EBEBEB\" />\n            <stop offset=\"1\" stop-color=\"white\" />\n          </linearGradient>\n        </defs>\n      </svg>`\n  }\n\n}\n\ndeclare global {\n  interface HTMLElementTagNameMap {\n    'weight-knob': WeightKnob;\n  }\n}\n"},{"path":"index.tsx","content":"/**\n * @fileoverview Control real time music with a MIDI controller\n * @license\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport type { PlaybackState, Prompt } from './types';\nimport { GoogleGenAI, LiveMusicFilteredPrompt } from '@google/genai';\nimport { PromptDjMidi } from './components/PromptDjMidi';\nimport { ToastMessage } from './components/ToastMessage';\nimport { LiveMusicHelper } from './utils/LiveMusicHelper';\nimport { AudioAnalyser } from './utils/AudioAnalyser';\n\nconst ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY, apiVersion: 'v1alpha' });\nconst model = 'lyria-realtime-exp';\n\nfunction main() {\n  const initialPrompts = buildInitialPrompts();\n\n  const pdjMidi = new PromptDjMidi(initialPrompts);\n  document.body.appendChild(pdjMidi);\n\n  const toastMessage = new ToastMessage();\n  document.body.appendChild(toastMessage);\n\n  const liveMusicHelper = new LiveMusicHelper(ai, model);\n  liveMusicHelper.setWeightedPrompts(initialPrompts);\n\n  const audioAnalyser = new AudioAnalyser(liveMusicHelper.audioContext);\n  liveMusicHelper.extraDestination = audioAnalyser.node;\n\n  pdjMidi.addEventListener('prompts-changed', ((e: Event) => {\n    const customEvent = e as CustomEvent<Map<string, Prompt>>;\n    const prompts = customEvent.detail;\n    liveMusicHelper.setWeightedPrompts(prompts);\n  }));\n\n  pdjMidi.addEventListener('play-pause', () => {\n    liveMusicHelper.playPause();\n  });\n\n  liveMusicHelper.addEventListener('playback-state-changed', ((e: Event) => {\n    const customEvent = e as CustomEvent<PlaybackState>;\n    const playbackState = customEvent.detail;\n    pdjMidi.playbackState = playbackState;\n    playbackState === 'playing' ? audioAnalyser.start() : audioAnalyser.stop();\n  }));\n\n  liveMusicHelper.addEventListener('filtered-prompt', ((e: Event) => {\n    const customEvent = e as CustomEvent<LiveMusicFilteredPrompt>;\n    const filteredPrompt = customEvent.detail;\n    toastMessage.show(filteredPrompt.filteredReason!)\n    pdjMidi.addFilteredPrompt(filteredPrompt.text!);\n  }));\n\n  const errorToast = ((e: Event) => {\n    const customEvent = e as CustomEvent<string>;\n    const error = customEvent.detail;\n    toastMessage.show(error);\n  });\n\n  liveMusicHelper.addEventListener('error', errorToast);\n  pdjMidi.addEventListener('error', errorToast);\n\n  audioAnalyser.addEventListener('audio-level-changed', ((e: Event) => {\n    const customEvent = e as CustomEvent<number>;\n    const level = customEvent.detail;\n    pdjMidi.audioLevel = level;\n  }));\n\n}\n\nfunction buildInitialPrompts() {\n  // Pick 3 random prompts to start at weight = 1\n  const startOn = [...DEFAULT_PROMPTS]\n    .sort(() => Math.random() - 0.5)\n    .slice(0, 3);\n\n  const prompts = new Map<string, Prompt>();\n\n  for (let i = 0; i < DEFAULT_PROMPTS.length; i++) {\n    const promptId = `prompt-${i}`;\n    const prompt = DEFAULT_PROMPTS[i];\n    const { text, color } = prompt;\n    prompts.set(promptId, {\n      promptId,\n      text,\n      weight: startOn.includes(prompt) ? 1 : 0,\n      cc: i,\n      color,\n    });\n  }\n\n  return prompts;\n}\n\nconst DEFAULT_PROMPTS = [\n  { color: '#9900ff', text: 'Bossa Nova' },\n  { color: '#5200ff', text: 'Chillwave' },\n  { color: '#ff25f6', text: 'Drum and Bass' },\n  { color: '#2af6de', text: 'Post Punk' },\n  { color: '#ffdd28', text: 'Shoegaze' },\n  { color: '#2af6de', text: 'Funk' },\n  { color: '#9900ff', text: 'Chiptune' },\n  { color: '#3dffab', text: 'Lush Strings' },\n  { color: '#d8ff3e', text: 'Sparkling Arpeggios' },\n  { color: '#d9b2ff', text: 'Staccato Rhythms' },\n  { color: '#3dffab', text: 'Punchy Kick' },\n  { color: '#ffdd28', text: 'Dubstep' },\n  { color: '#ff25f6', text: 'K Pop' },\n  { color: '#d8ff3e', text: 'Neo Soul' },\n  { color: '#5200ff', text: 'Trip Hop' },\n  { color: '#d9b2ff', text: 'Thrash' },\n];\n\nmain();\n"},{"path":"types.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nexport interface Prompt {\n  readonly promptId: string;\n  text: string;\n  weight: number;\n  cc: number;\n  color: string;\n}\n\nexport interface ControlChange {\n  channel: number;\n  cc: number;\n  value: number;\n}\n\nexport type PlaybackState = 'stopped' | 'playing' | 'loading' | 'paused';\n"},{"path":"utils/AudioAnalyser.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\n/** Simple class for getting the current audio level. */\nexport class AudioAnalyser extends EventTarget {\n  readonly node: AnalyserNode;\n  private readonly freqData: Uint8Array;\n  private rafId: number | null = null;\n  constructor(context: AudioContext) {\n    super();\n    this.node = context.createAnalyser();\n    this.node.smoothingTimeConstant = 0;\n    this.freqData = new Uint8Array(this.node.frequencyBinCount);\n    this.loop = this.loop.bind(this);\n  }\n  getCurrentLevel() {\n    this.node.getByteFrequencyData(this.freqData);\n    const avg = this.freqData.reduce((a, b) => a + b, 0) / this.freqData.length;\n    return avg / 0xff;\n  }\n  loop() {\n    this.rafId = requestAnimationFrame(this.loop);\n    const level = this.getCurrentLevel();\n    this.dispatchEvent(new CustomEvent('audio-level-changed', { detail: level }));\n  }\n  start = this.loop;\n  stop() {\n    if (this.rafId) cancelAnimationFrame(this.rafId);\n  }\n}\n"},{"path":"utils/LiveMusicHelper.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nimport type { PlaybackState, Prompt } from '../types';\nimport type { AudioChunk, GoogleGenAI, LiveMusicFilteredPrompt, LiveMusicServerMessage, LiveMusicSession } from '@google/genai';\nimport { decode, decodeAudioData } from './audio';\nimport { throttle } from './throttle';\n\nexport class LiveMusicHelper extends EventTarget {\n\n  private ai: GoogleGenAI;\n  private model: string;\n\n  private session: LiveMusicSession | null = null;\n  private sessionPromise: Promise<LiveMusicSession> | null = null;\n\n  private connectionError = true;\n\n  private filteredPrompts = new Set<string>();\n  private nextStartTime = 0;\n  private bufferTime = 2;\n\n  public readonly audioContext: AudioContext;\n  public extraDestination: AudioNode | null = null;\n\n  private outputNode: GainNode;\n  private playbackState: PlaybackState = 'stopped';\n\n  private prompts: Map<string, Prompt>;\n\n  constructor(ai: GoogleGenAI, model: string) {\n    super();\n    this.ai = ai;\n    this.model = model;\n    this.prompts = new Map();\n    this.audioContext = new AudioContext({ sampleRate: 48000 });\n    this.outputNode = this.audioContext.createGain();\n  }\n\n  private getSession(): Promise<LiveMusicSession> {\n    if (!this.sessionPromise) this.sessionPromise = this.connect();\n    return this.sessionPromise;\n  }\n\n  private async connect(): Promise<LiveMusicSession> {\n    this.sessionPromise = this.ai.live.music.connect({\n      model: this.model,\n      callbacks: {\n        onmessage: async (e: LiveMusicServerMessage) => {\n          if (e.setupComplete) {\n            this.connectionError = false;\n          }\n          if (e.filteredPrompt) {\n            this.filteredPrompts = new Set([...this.filteredPrompts, e.filteredPrompt.text!])\n            this.dispatchEvent(new CustomEvent<LiveMusicFilteredPrompt>('filtered-prompt', { detail: e.filteredPrompt }));\n          }\n          if (e.serverContent?.audioChunks) {\n            await this.processAudioChunks(e.serverContent.audioChunks);\n          }\n        },\n        onerror: () => {\n          this.connectionError = true;\n          this.stop();\n          this.dispatchEvent(new CustomEvent('error', { detail: 'Connection error, please restart audio.' }));\n        },\n        onclose: () => {\n          this.connectionError = true;\n          this.stop();\n          this.dispatchEvent(new CustomEvent('error', { detail: 'Connection error, please restart audio.' }));\n        },\n      },\n    });\n    return this.sessionPromise;\n  }\n\n  private setPlaybackState(state: PlaybackState) {\n    this.playbackState = state;\n    this.dispatchEvent(new CustomEvent('playback-state-changed', { detail: state }));\n  }\n\n  private async processAudioChunks(audioChunks: AudioChunk[]) {\n    if (this.playbackState === 'paused' || this.playbackState === 'stopped') return;\n    const audioBuffer = await decodeAudioData(\n      decode(audioChunks[0].data!),\n      this.audioContext,\n      48000,\n      2,\n    );\n    const source = this.audioContext.createBufferSource();\n    source.buffer = audioBuffer;\n    source.connect(this.outputNode);\n    if (this.nextStartTime === 0) {\n      this.nextStartTime = this.audioContext.currentTime + this.bufferTime;\n      setTimeout(() => {\n        this.setPlaybackState('playing');\n      }, this.bufferTime * 1000);\n    }\n    if (this.nextStartTime < this.audioContext.currentTime) {\n      this.setPlaybackState('loading');\n      this.nextStartTime = 0;\n      return;\n    }\n    source.start(this.nextStartTime);\n    this.nextStartTime += audioBuffer.duration;\n  }\n\n  public get activePrompts() {\n    return Array.from(this.prompts.values())\n      .filter((p) => {\n        return !this.filteredPrompts.has(p.text) && p.weight !== 0;\n      })\n  }\n\n  public readonly setWeightedPrompts = throttle(async (prompts: Map<string, Prompt>) => {\n    this.prompts = prompts;\n\n    if (this.activePrompts.length === 0) {\n      this.dispatchEvent(new CustomEvent('error', { detail: 'There needs to be one active prompt to play.' }));\n      this.pause();\n      return;\n    }\n\n    // store the prompts to set later if we haven't connected yet\n    // there should be a user interaction before calling setWeightedPrompts\n    if (!this.session) return;\n\n    try {\n      await this.session.setWeightedPrompts({\n        weightedPrompts: this.activePrompts,\n      });\n    } catch (e: any) {\n      this.dispatchEvent(new CustomEvent('error', { detail: e.message }));\n      this.pause();\n    }\n  }, 200);\n\n  public async play() {\n    this.setPlaybackState('loading');\n    this.session = await this.getSession();\n    await this.setWeightedPrompts(this.prompts);\n    this.audioContext.resume();\n    this.session.play();\n    this.outputNode.connect(this.audioContext.destination);\n    if (this.extraDestination) this.outputNode.connect(this.extraDestination);\n    this.outputNode.gain.setValueAtTime(0, this.audioContext.currentTime);\n    this.outputNode.gain.linearRampToValueAtTime(1, this.audioContext.currentTime + 0.1);\n  }\n\n  public pause() {\n    if (this.session) this.session.pause();\n    this.setPlaybackState('paused');\n    this.outputNode.gain.setValueAtTime(1, this.audioContext.currentTime);\n    this.outputNode.gain.linearRampToValueAtTime(0, this.audioContext.currentTime + 0.1);\n    this.nextStartTime = 0;\n    this.outputNode = this.audioContext.createGain();\n  }\n\n  public stop() {\n    if (this.session) this.session.stop();\n    this.setPlaybackState('stopped');\n    this.outputNode.gain.setValueAtTime(0, this.audioContext.currentTime);\n    this.outputNode.gain.linearRampToValueAtTime(1, this.audioContext.currentTime + 0.1);\n    this.nextStartTime = 0;\n    this.session = null;\n    this.sessionPromise = null;\n  }\n\n  public async playPause() {\n    switch (this.playbackState) {\n      case 'playing':\n        return this.pause();\n      case 'paused':\n      case 'stopped':\n        return this.play();\n      case 'loading':\n        return this.stop();\n    }\n  }\n\n}\n"},{"path":"utils/MidiDispatcher.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\nimport type { ControlChange } from '../types';\n\n/** Simple class for dispatching MIDI CC messages as events. */\nexport class MidiDispatcher extends EventTarget {\n  private access: MIDIAccess | null = null;\n  activeMidiInputId: string | null = null;\n\n  async getMidiAccess(): Promise<string[]> {\n\n    if (this.access) {\n      return [...this.access.inputs.keys()];\n    }\n\n    if (!navigator.requestMIDIAccess) {\n      throw new Error('Your browser does not support the Web MIDI API. For a list of compatible browsers, see https://caniuse.com/midi');\n    }\n\n    this.access = await navigator\n      .requestMIDIAccess({ sysex: false })\n      .catch((error) => error);\n\n    if (this.access === null) {\n      throw new Error('Unable to acquire MIDI access.');\n    }\n\n    const inputIds = [...this.access.inputs.keys()];\n\n    if (inputIds.length > 0 && this.activeMidiInputId === null) {\n      this.activeMidiInputId = inputIds[0];\n    }\n\n    for (const input of this.access.inputs.values()) {\n      input.onmidimessage = (event: MIDIMessageEvent) => {\n        if (input.id !== this.activeMidiInputId) return;\n\n        const { data } = event;\n        if (!data) {\n          console.error('MIDI message has no data');\n          return;\n        }\n\n        const statusByte = data[0];\n        const channel = statusByte & 0x0f;\n        const messageType = statusByte & 0xf0;\n\n        const isControlChange = messageType === 0xb0;\n        if (!isControlChange) return;\n\n        const detail: ControlChange = { cc: data[1], value: data[2], channel };\n        this.dispatchEvent(\n          new CustomEvent<ControlChange>('cc-message', { detail }),\n        );\n      };\n    }\n\n    return inputIds;\n  }\n\n  getDeviceName(id: string): string | null {\n    if (!this.access) {\n      return null;\n    }\n    const input = this.access.inputs.get(id);\n    return input ? input.name : null;\n  }\n}\n"},{"path":"utils/audio.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\n\nimport {Blob} from '@google/genai';\n\nfunction encode(bytes: Uint8Array) {\n  let binary = '';\n  const len = bytes.byteLength;\n  for (let i = 0; i < len; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return btoa(binary);\n}\n\nfunction decode(base64: string) {\n  const binaryString = atob(base64);\n  const len = binaryString.length;\n  const bytes = new Uint8Array(len);\n  for (let i = 0; i < len; i++) {\n    bytes[i] = binaryString.charCodeAt(i);\n  }\n  return bytes;\n}\n\nfunction createBlob(data: Float32Array): Blob {\n  const l = data.length;\n  const int16 = new Int16Array(l);\n  for (let i = 0; i < l; i++) {\n    // convert float32 -1 to 1 to int16 -32768 to 32767\n    int16[i] = data[i] * 32768;\n  }\n\n  return {\n    data: encode(new Uint8Array(int16.buffer)),\n    mimeType: 'audio/pcm;rate=16000',\n  };\n}\n\nasync function decodeAudioData(\n  data: Uint8Array,\n  ctx: AudioContext,\n  sampleRate: number,\n  numChannels: number,\n): Promise<AudioBuffer> {\n  const buffer = ctx.createBuffer(\n    numChannels,\n    data.length / 2 / numChannels,\n    sampleRate,\n  );\n\n  const dataInt16 = new Int16Array(data.buffer);\n  const l = dataInt16.length;\n  const dataFloat32 = new Float32Array(l);\n  for (let i = 0; i < l; i++) {\n    dataFloat32[i] = dataInt16[i] / 32768.0;\n  }\n  // Extract interleaved channels\n  if (numChannels === 0) {\n    buffer.copyToChannel(dataFloat32, 0);\n  } else {\n    for (let i = 0; i < numChannels; i++) {\n      const channel = dataFloat32.filter(\n        (_, index) => index % numChannels === i,\n      );\n      buffer.copyToChannel(channel, i);\n    }\n  }\n\n  return buffer;\n}\n\nexport {createBlob, decode, decodeAudioData, encode};\n"},{"path":"utils/throttle.ts","content":"/**\n * @license\n * SPDX-License-Identifier: Apache-2.0\n*/\n/**\n * Throttles a callback to be called at most once per `delay` milliseconds.\n * Also returns the result of the last \"fresh\" call...\n */\nexport function throttle<T extends (...args: Parameters<T>) => ReturnType<T>>(\n  func: T,\n  delay: number,\n): (...args: Parameters<T>) => ReturnType<T> {\n  let lastCall = -Infinity;\n  let lastResult: ReturnType<T>;\n  return (...args: Parameters<T>) => {\n    const now = Date.now();\n    const timeSinceLastCall = now - lastCall;\n    if (timeSinceLastCall >= delay) {\n      lastResult = func(...args);\n      lastCall = now;\n    }\n    return lastResult;\n  };\n}\n"},{"path":"vite.config.ts","content":"import path from 'path';\nimport { defineConfig, loadEnv } from 'vite';\n\n\nexport default defineConfig(({ mode }) => {\n    const env = loadEnv(mode, '.', '');\n    return {\n      server: {\n        port: 3000,\n        host: '0.0.0.0',\n      },\n      plugins: [],\n      define: {\n        'process.env.API_KEY': JSON.stringify(env.GEMINI_API_KEY),\n        'process.env.GEMINI_API_KEY': JSON.stringify(env.GEMINI_API_KEY)\n      },\n      resolve: {\n        alias: {\n          '@': path.resolve(__dirname, '.'),\n        }\n      }\n    };\n});\n"}]}

--- Artifact '__1/__step_2_AI Tutor_result.txt' from (AI Tutor) in [T3]:
{"output":"Hello Lex and Critique! I'm here to facilitate our knowledge transfer regarding the PromptDJ MIDI myfirstanalog project. Our collective goal is to document this project thoroughly. \n\n**Project Overview:**\nThe PromptDJ MIDI myfirstanalog project is a web application that allows users to control real-time music generation using a MIDI controller. It leverages AI, specifically Google's Gemini models (Lyria-realtime-exp), to generate music based on text prompts. These prompts can be dynamically controlled and mapped to MIDI Continuous Controller (CC) messages. The project is built using LitElement for web components and Vite for its build process.\n\n**Architecture:**\n- **Frontend:** Primarily built with LitElement, creating reusable web components for UI elements like buttons, knobs, and controllers. The main application logic resides in `index.tsx`.\n- **AI Integration:** Uses the `@google/genai` library to interact with the Lyria-realtime-exp model for music generation.\n- **MIDI Control:** Employs the Web MIDI API through a `MidiDispatcher` utility to map MIDI CC messages to prompt weights and other controls.\n- **Audio Handling:** Includes utilities for audio analysis (`AudioAnalyser`), decoding/encoding (`audio.ts`), and managing audio playback (`LiveMusicHelper`).\n- **State Management:** Primarily managed within components and passed down via properties and events. `PromptController` components manage individual prompt settings.\n- **Build Tool:** Vite is used for development, building, and previewing the application.\n\n**Documentation Requirements:**\nWe have a set of Task Agnostic Steps (TAS) that need to be addressed. For each TAS, Lex will generate the initial documentation, and Critique will review it. My role here is to ensure you both understand the context and the specific requirements for each task.\n\n**Lex (Documentation Writer):** Your prompts guide you to create documentation for various parts of the project. Remember to refer to the provided code snippets for accuracy. Focus on explaining the 'what,' 'why,' and 'how' of each piece of code or configuration.\n\n**Critique (Documentation Reviewer):** Your prompts guide you to critically evaluate Lex's output. Ensure you are providing specific, actionable feedback based on clarity, accuracy, completeness, and adherence to technical writing standards. Your goal is to refine the documentation.\n\n**Key Files and Their Roles:**\n- `README.md`: Project overview, setup, and usage.\n- `package.json`: Project dependencies and scripts.\n- `metadata.json`: Application metadata for AI Studio.\n- `tsconfig.json`: TypeScript compiler options.\n- `components/`: Directory containing UI web components (e.g., `PlayPauseButton`, `PromptController`, `WeightKnob`).\n- `utils/`: Directory for utility functions (e.g., `MidiDispatcher`, `AudioAnalyser`, `throttle`).\n- `index.tsx`: Main application entry point.\n- `types.ts`: Defines core data structures.\n- `vite.config.ts`: Vite build configuration.\n\nLet's proceed with the tasks. Lex, you should expect to receive the first prompt for generating documentation based on the identified TAS. Critique, you will then review Lex's output. I'm here to clarify any points as we go.\n\nAre you both ready to begin with the first documentation task?","artifact":null,"team":{"notes":"Provided context and knowledge transfer to Lex and Critique regarding the PromptDJ MIDI myfirstanalog project, its architecture, and the specific documentation requirements for each TAS. This sets the stage for the subsequent documentation generation and review tasks.","prompts":[]},"reasoning":"As the AI Tutor, my sub-task is to provide context and knowledge transfer to Lex and Critique. I have synthesized the information about the project's goal, architecture, and the roles of Lex and Critique. I've outlined the key files and their purposes, and explicitly stated the documentation requirements for each TAS. The output is a conversational message aimed at ensuring both agents have a shared understanding before proceeding with their respective tasks. This fulfills the 'Knowledge transfer between spaces' goal."}



Please execute your sub-task, keeping the overall goal and your role's specific goal in mind to ensure your output is relevant to the project.